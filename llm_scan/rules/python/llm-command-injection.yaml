rules:
  - id: llm-command-injection-subprocess
    patterns:
      - pattern-either:
          - pattern: |
              $RESPONSE = openai.ChatCompletion.create(...)
          - pattern: |
              $RESPONSE = openai.Completion.create(...)
          - pattern: |
              $RESPONSE = $CLIENT.chat.completions.create(...)
          - pattern: |
              $RESPONSE = $CLIENT.messages.create(...)
      - pattern-either:
          - pattern: subprocess.run($VAR, ...)
          - pattern: subprocess.call($VAR, ...)
          - pattern: subprocess.Popen($VAR, ...)
          - pattern: os.system($VAR)
          - pattern: os.popen($VAR)
      - metavariable-regex:
          metavariable: $VAR
          regex: (code|content|text|output|result|response|command|cmd|str|message|data|resp|answer)
    message: "LLM output is passed to subprocess/os.system, which can lead to command injection"
    severity: ERROR
    languages: [python]
    metadata:
      category: security
      subcategory: command-injection
      cwe: ["CWE-78"]
      cwe-url: ["https://cwe.mitre.org/data/definitions/78.html"]
      tags: ["command-injection", "subprocess", "os.system", "llm", "ai-security", "injection"]
      technology: ["python", "openai", "anthropic", "llm"]
      confidence: "high"
      impact: "critical"
      likelihood: "high"
      description: "LLM output is passed to subprocess.run(), subprocess.call(), subprocess.Popen(), or os.system() without validation, allowing command injection if the LLM output contains shell commands."
      remediation: "Never execute LLM output as shell commands. Use subprocess with shell=False and validate inputs. Use command whitelists and parameterized commands."
      examples:
        vulnerable: "samples/vulnerable_app.py"
      references:
        - "https://owasp.org/www-community/attacks/Command_Injection"
        - "https://cwe.mitre.org/data/definitions/78.html"
    paths:
      include:
        - "*.py"

  - id: llm-command-injection-shell
    patterns:
      - pattern-either:
          - pattern: subprocess.run($VAR, shell=True, ...)
          - pattern: subprocess.call($VAR, shell=True, ...)
          - pattern: subprocess.Popen($VAR, shell=True, ...)
      - pattern-inside: |
          $RESPONSE = openai.ChatCompletion.create(...)
          ...
      - metavariable-regex:
          metavariable: $VAR
          regex: (code|content|text|output|result|response|command|cmd|str|message|data|resp|answer)
    message: "LLM output is passed to subprocess with shell=True, enabling command injection"
    severity: ERROR
    languages: [python]
    metadata:
      category: security
      subcategory: command-injection
      cwe: ["CWE-78"]
      cwe-url: ["https://cwe.mitre.org/data/definitions/78.html"]
      tags: ["command-injection", "subprocess", "shell", "llm", "ai-security", "injection", "shell-true"]
      technology: ["python", "openai", "anthropic", "llm"]
      confidence: "high"
      impact: "critical"
      likelihood: "high"
      description: "LLM output is passed to subprocess functions with shell=True, which enables shell interpretation and makes command injection attacks easier."
      remediation: "Never use shell=True with untrusted input. Use shell=False and pass commands as lists. Validate and sanitize all command arguments."
      examples:
        vulnerable: "samples/vulnerable_app.py"
      references:
        - "https://owasp.org/www-community/attacks/Command_Injection"
        - "https://cwe.mitre.org/data/definitions/78.html"
    paths:
      include:
        - "*.py"
