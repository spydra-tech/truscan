rules:
  - id: llm-code-injection-eval
    patterns:
      - pattern-either:
          - pattern: |
              $RESPONSE = openai.ChatCompletion.create(...)
          - pattern: |
              $RESPONSE = openai.Completion.create(...)
          - pattern: |
              $RESPONSE = $CLIENT.chat.completions.create(...)
          - pattern: |
              $RESPONSE = $CLIENT.messages.create(...)
      - pattern-either:
          - pattern: eval($VAR)
          - pattern: exec($VAR)
          - pattern: compile($VAR, ...)
      - metavariable-regex:
          metavariable: $VAR
          regex: (code|content|text|output|result|response|command|cmd|str|message|data|resp|answer)
    message: "LLM output is passed to eval/exec/compile, which can lead to code injection"
    severity: ERROR
    languages: [python]
    metadata:
      category: security
      subcategory: code-injection
      cwe: ["CWE-94"]
      cwe-url: ["https://cwe.mitre.org/data/definitions/94.html"]
      tags: ["code-injection", "eval", "exec", "compile", "llm", "ai-security", "injection"]
      technology: ["python", "openai", "anthropic", "llm"]
      confidence: "high"
      impact: "critical"
      likelihood: "high"
      description: "LLM output is passed to eval(), exec(), or compile() functions without validation, allowing arbitrary code execution if the LLM output contains malicious code."
      remediation: "Never execute LLM output as code. Use safe parsing and validation instead. Use AST parsing, whitelisted operations, or structured output formats (JSON, YAML) instead of code execution."
      examples:
        vulnerable: "samples/vulnerable_app.py"
      references:
        - "https://owasp.org/www-community/vulnerabilities/Code_Injection"
        - "https://cwe.mitre.org/data/definitions/94.html"
    paths:
      include:
        - "*.py"

  - id: llm-code-injection-eval-direct
    patterns:
      - pattern-either:
          - pattern: eval($VAR)
          - pattern: exec($VAR)
          - pattern: compile($VAR, ...)
      - pattern-inside: |
          $RESPONSE = openai.ChatCompletion.create(...)
          ...
      - metavariable-regex:
          metavariable: $VAR
          regex: (code|content|text|output|result|response|command|cmd|str|message|data|resp|answer)
    message: "LLM response is directly passed to eval/exec/compile"
    severity: ERROR
    languages: [python]
    metadata:
      category: security
      subcategory: code-injection
      cwe: ["CWE-94"]
      cwe-url: ["https://cwe.mitre.org/data/definitions/94.html"]
      tags: ["code-injection", "eval", "exec", "compile", "llm", "ai-security", "injection", "direct"]
      technology: ["python", "openai", "anthropic", "llm"]
      confidence: "high"
      impact: "critical"
      likelihood: "high"
      description: "LLM response content is directly extracted and passed to eval(), exec(), or compile() without any intermediate processing or validation."
      remediation: "Never execute LLM output as code. Validate and sanitize all LLM outputs. Use structured output parsing instead of code execution."
      examples:
        vulnerable: "samples/vulnerable_app.py"
      references:
        - "https://owasp.org/www-community/vulnerabilities/Code_Injection"
        - "https://cwe.mitre.org/data/definitions/94.html"
    paths:
      include:
        - "*.py"
