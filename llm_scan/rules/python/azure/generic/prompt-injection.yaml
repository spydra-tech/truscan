rules:
  # ============================================================================
  # LLM01: Prompt Injection - Azure OpenAI Service Generic (AI-Enhanced Detection)
  # ============================================================================
  # This rule set is designed to work with AI analysis to reduce false positives.
  # Semgrep catches potential patterns broadly, AI determines exploitability.
  # 
  # Usage with AI:
  #   python -m llm_scan.runner . --enable-ai-filter \
  #     --ai-analyze-rules azure-llm01-prompt-injection-direct \
  #     --ai-analyze-rules azure-llm01-prompt-injection-concatenation \
  #     --ai-analyze-rules azure-llm01-prompt-injection-system
  #
  # OWASP: LLM01
  # CWE: CWE-79, CWE-94
  # ============================================================================

  - id: azure-llm01-prompt-injection-direct
    patterns:
      - pattern-either:
          # Direct user input in chat messages
          - pattern: |
              AzureOpenAI().chat.completions.create(messages=[..., {"role": "user", "content": $USER_INPUT}, ...])
          - pattern: |
              AzureOpenAI().chat.completions.create(messages=[..., {"content": $USER_INPUT}, ...])
          - pattern: |
              $CLIENT.chat.completions.create(messages=[..., {"role": "user", "content": $USER_INPUT}, ...])
          - pattern: |
              $CLIENT.chat.completions.create(messages=[..., {"content": $USER_INPUT}, ...])
          - pattern: |
              openai.AzureOpenAI(...).chat.completions.create(messages=[..., {"role": "user", "content": $USER_INPUT}, ...])
          - pattern: |
              openai.AzureOpenAI(...).chat.completions.create(messages=[..., {"content": $USER_INPUT}, ...])
      # Only exclude well-known standard library/framework escaping functions
      # AI will analyze if custom sanitization is sufficient
      - pattern-not-inside: |
          $SANITIZED = html.escape($USER_INPUT)
          ...
      - pattern-not-inside: |
          $SANITIZED = markupsafe.escape($USER_INPUT)
          ...
      - pattern-not-inside: |
          $SANITIZED = bleach.clean($USER_INPUT)
          ...
      - metavariable-regex:
          metavariable: $USER_INPUT
          regex: (request\.|input\(|sys\.argv|getenv|environ|args|kwargs|params|query|body|form|json|data|user_input|user_input_text|user_message|user_prompt|prompt_text|raw_input|raw_prompt|user_data|user_content)
    message: "LLM01: Potential Prompt Injection - User input directly inserted into Azure OpenAI prompt"
    severity: ERROR
    languages: [python]
    metadata:
      category: security
      subcategory: injection
      owasp: "LLM01"
      owasp-title: "Prompt Injection"
      owasp-url: "https://owasp.org/www-project-top-10-for-large-language-model-applications/LLM_Top_10/LLM01.html"
      cwe: ["CWE-79", "CWE-94"]
      cwe-url: ["https://cwe.mitre.org/data/definitions/79.html", "https://cwe.mitre.org/data/definitions/94.html"]
      tags: ["owasp", "llm01", "prompt-injection", "injection", "input-validation", "llm", "ai-security", "azure", "azure-openai", "ai-enhanced"]
      technology: ["python", "azure", "openai", "llm"]
      confidence: "medium"  # Medium confidence - AI will analyze to determine if exploitable
      impact: "critical"
      likelihood: "medium"  # AI will assess actual likelihood based on context
      description: "User input is directly inserted into Azure OpenAI prompts. This pattern may be vulnerable to prompt injection if input is not properly sanitized or validated. AI analysis will determine if the vulnerability is actually exploitable based on code context, sanitization, and validation."
      remediation: "Sanitize and validate all user input before including in prompts. Use prompt templates with parameterized inputs. Implement input validation, output encoding, and prompt engineering best practices. Consider using delimiters to separate user data from instructions. Leverage Azure OpenAI Prompt Shields for additional protection."
      ai_analysis_recommended: false
      examples:
        vulnerable: "samples/azure_prompt_injection.py"
      references:
        - "https://owasp.org/www-project-top-10-for-large-language-model-applications/"
        - "https://learnprompting.org/docs/category/-prompt-injection"
        - "https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/content-filter-prompt-shields"
    paths:
      include:
        - "**/*.py"

  - id: azure-llm01-prompt-injection-concatenation
    patterns:
      - pattern-either:
          # String concatenation in chat prompts
          - pattern: |
              AzureOpenAI().chat.completions.create(messages=[..., {"role": "user", "content": $PROMPT + $USER_INPUT}, ...])
          - pattern: |
              AzureOpenAI().chat.completions.create(messages=[..., {"content": $PROMPT + $USER_INPUT}, ...])
          - pattern: |
              $CLIENT.chat.completions.create(messages=[..., {"role": "user", "content": $PROMPT + $USER_INPUT}, ...])
          - pattern: |
              $CLIENT.chat.completions.create(messages=[..., {"content": $PROMPT + $USER_INPUT}, ...])
          # F-string interpolation
          - pattern: |
              AzureOpenAI().chat.completions.create(messages=[..., {"role": "user", "content": f"...{$USER_INPUT}..."}, ...])
          - pattern: |
              AzureOpenAI().chat.completions.create(messages=[..., {"content": f"...{$USER_INPUT}..."}, ...])
          - pattern: |
              $CLIENT.chat.completions.create(messages=[..., {"role": "user", "content": f"...{$USER_INPUT}..."}, ...])
          - pattern: |
              $CLIENT.chat.completions.create(messages=[..., {"content": f"...{$USER_INPUT}..."}, ...])
          # Variable assignment before API call
          - pattern: |
              $PROMPT = ... + $USER_INPUT + ...
              ...
              AzureOpenAI().chat.completions.create(messages=[..., {"content": $PROMPT}, ...])
          - pattern: |
              $PROMPT = f"...{$USER_INPUT}..."
              ...
              AzureOpenAI().chat.completions.create(messages=[..., {"content": $PROMPT}, ...])
      - metavariable-regex:
          metavariable: $USER_INPUT
          regex: (request\.|input\(|sys\.argv|getenv|environ|args|kwargs|params|query|body|form|json|data|user_input|user_input_text|user_message|user_prompt|prompt_text|raw_input|raw_prompt|user_data|user_content)
    message: "LLM01: Potential Prompt Injection - User input concatenated into Azure OpenAI prompt"
    severity: ERROR
    languages: [python]
    metadata:
      category: security
      subcategory: injection
      owasp: "LLM01"
      owasp-title: "Prompt Injection"
      owasp-url: "https://owasp.org/www-project-top-10-for-large-language-model-applications/LLM_Top_10/LLM01.html"
      cwe: ["CWE-79", "CWE-94"]
      cwe-url: ["https://cwe.mitre.org/data/definitions/79.html", "https://cwe.mitre.org/data/definitions/94.html"]
      tags: ["owasp", "llm01", "prompt-injection", "injection", "input-validation", "llm", "ai-security", "azure", "azure-openai", "ai-enhanced"]
      technology: ["python", "azure", "openai", "llm"]
      confidence: "medium"  # Medium confidence - AI will analyze to determine if exploitable
      impact: "critical"
      likelihood: "medium"  # AI will assess actual likelihood based on context
      description: "User input is concatenated into Azure OpenAI prompts using string concatenation or f-strings. This pattern may be vulnerable to prompt injection if input is not properly sanitized or validated. AI analysis will determine if the vulnerability is actually exploitable based on code context, sanitization, and validation."
      remediation: "Sanitize and validate all user input before including in prompts. Use prompt templates with parameterized inputs. Implement input validation, output encoding, and prompt engineering best practices. Consider using delimiters to separate user data from instructions. Leverage Azure OpenAI Prompt Shields for additional protection."
      ai_analysis_recommended: false
      examples:
        vulnerable: "samples/azure_prompt_injection.py"
      references:
        - "https://owasp.org/www-project-top-10-for-large-language-model-applications/"
        - "https://learnprompting.org/docs/category/-prompt-injection"
        - "https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/content-filter-prompt-shields"
    paths:
      include:
        - "**/*.py"

  - id: azure-llm01-prompt-injection-system
    patterns:
      - pattern-either:
          # User input in system messages
          - pattern: |
              AzureOpenAI().chat.completions.create(messages=[{"role": "system", "content": $USER_INPUT}, ...])
          - pattern: |
              $CLIENT.chat.completions.create(messages=[{"role": "system", "content": $USER_INPUT}, ...])
          - pattern: |
              openai.AzureOpenAI(...).chat.completions.create(messages=[{"role": "system", "content": $USER_INPUT}, ...])
      - metavariable-regex:
          metavariable: $USER_INPUT
          regex: (request\.|input\(|sys\.argv|getenv|environ|args|kwargs|params|query|body|form|json|data|user_input|user_input_text|user_message|user_prompt|prompt_text|raw_input|raw_prompt|user_data|user_content)
    message: "LLM01: Prompt Injection - User input in Azure OpenAI system prompt (critical vulnerability)"
    severity: ERROR
    languages: [python]
    metadata:
      category: security
      subcategory: injection
      owasp: "LLM01"
      owasp-title: "Prompt Injection (System Prompt)"
      owasp-url: "https://owasp.org/www-project-top-10-for-large-language-model-applications/LLM_Top_10/LLM01.html"
      cwe: ["CWE-79", "CWE-94"]
      cwe-url: ["https://cwe.mitre.org/data/definitions/79.html", "https://cwe.mitre.org/data/definitions/94.html"]
      tags: ["owasp", "llm01", "prompt-injection", "injection", "system-prompt", "llm", "ai-security", "azure", "azure-openai", "ai-enhanced"]
      technology: ["python", "azure", "openai", "llm"]
      confidence: "high"
      impact: "critical"
      likelihood: "high"
      description: "User input is inserted into Azure OpenAI system prompts. System prompts define model behavior, and allowing user control enables complete model manipulation, jailbreaking, and security control bypass. This is a critical vulnerability."
      remediation: "NEVER allow user input in system prompts. System prompts must be hardcoded or from trusted configuration sources only. Validate and sanitize all system prompt content. Use separate system prompts for different use cases."
      ai_analysis_recommended: false
      examples:
        vulnerable: "samples/azure_prompt_injection.py"
      references:
        - "https://owasp.org/www-project-top-10-for-large-language-model-applications/"
        - "https://learnprompting.org/docs/category/-prompt-injection"
    paths:
      include:
        - "**/*.py"
