rules:
  # Taint source: OpenAI legacy API
  - id: llm-openai-legacy-chat
    patterns:
      - pattern: openai.ChatCompletion.create(...)
      - metavariable-regex:
          metavariable: $VAR
          regex: (response|resp|result|output|answer|content|text|message)
    message: "OpenAI ChatCompletion API call detected"
    severity: INFO
    languages: [python]
    metadata:
      category: inventory
      subcategory: llm-api-detection
      tags: ["inventory", "openai", "legacy-api", "llm", "api-detection"]
      technology: ["python", "openai", "llm"]
      confidence: "high"
      impact: "info"
      likelihood: "n/a"
      description: "OpenAI ChatCompletion API call detected. This is an inventory rule to track LLM API usage in the codebase."
      remediation: "No remediation needed - this is an informational finding."
      examples:
        vulnerable: "samples/vulnerable_app.py"
      references:
        - "https://platform.openai.com/docs/api-reference/chat"
    paths:
      include:
        - "*.py"

  - id: llm-openai-legacy-completion
    patterns:
      - pattern: openai.Completion.create(...)
      - metavariable-regex:
          metavariable: $VAR
          regex: (response|resp|result|output|answer|content|text)
    message: "OpenAI Completion API call detected"
    severity: INFO
    languages: [python]
    metadata:
      category: inventory
      subcategory: llm-api-detection
      tags: ["inventory", "openai", "legacy-api", "completion", "llm", "api-detection"]
      technology: ["python", "openai", "llm"]
      confidence: "high"
      impact: "info"
      likelihood: "n/a"
      description: "OpenAI Completion API call detected. This is an inventory rule to track LLM API usage in the codebase."
      remediation: "No remediation needed - this is an informational finding."
      examples:
        vulnerable: "samples/vulnerable_app.py"
      references:
        - "https://platform.openai.com/docs/api-reference/completions"
    paths:
      include:
        - "*.py"

  # Taint source: OpenAI v1 client
  - id: llm-openai-v1-client
    patterns:
      - pattern: $CLIENT = OpenAI(...)
      - pattern-inside: |
          ...
          $RESPONSE = $CLIENT.chat.completions.create(...)
    message: "OpenAI v1 client usage detected"
    severity: INFO
    languages: [python]
    metadata:
      category: inventory
      subcategory: llm-api-detection
      tags: ["inventory", "openai", "v1-api", "llm", "api-detection"]
      technology: ["python", "openai", "llm"]
      confidence: "high"
      impact: "info"
      likelihood: "n/a"
      description: "OpenAI v1 client usage detected. This is an inventory rule to track LLM API usage in the codebase."
      remediation: "No remediation needed - this is an informational finding."
      examples:
        vulnerable: "samples/vulnerable_app.py"
      references:
        - "https://platform.openai.com/docs/api-reference"
    paths:
      include:
        - "*.py"

  # Taint source: Anthropic
  - id: llm-anthropic-client
    patterns:
      - pattern: $CLIENT = Anthropic(...)
      - pattern-inside: |
          ...
          $RESPONSE = $CLIENT.messages.create(...)
    message: "Anthropic client usage detected"
    severity: INFO
    languages: [python]
    metadata:
      category: inventory
      subcategory: llm-api-detection
      tags: ["inventory", "anthropic", "llm", "api-detection"]
      technology: ["python", "anthropic", "llm"]
      confidence: "high"
      impact: "info"
      likelihood: "n/a"
      description: "Anthropic client usage detected. This is an inventory rule to track LLM API usage in the codebase."
      remediation: "No remediation needed - this is an informational finding."
      examples:
        vulnerable: "samples/vulnerable_app.py"
      references:
        - "https://docs.anthropic.com/claude/reference/messages_post"
    paths:
      include:
        - "*.py"

  # Complete taint flow: LLM output -> eval
  - id: llm-to-eval-complete
    pattern-either:
      - pattern: |
          $RESPONSE = openai.ChatCompletion.create(...)
          ...
          $CONTENT = $RESPONSE.choices[0].message.content
          ...
          eval($CONTENT)
      - pattern: |
          $RESPONSE = openai.ChatCompletion.create(...)
          ...
          $CONTENT = $RESPONSE.choices[0].message.content
          ...
          exec($CONTENT)
      - pattern: |
          $RESPONSE = openai.ChatCompletion.create(...)
          ...
          $CONTENT = $RESPONSE.choices[0].message.content
          ...
          compile($CONTENT, ...)
      - pattern: |
          $RESPONSE = openai.Completion.create(...)
          ...
          $CONTENT = $RESPONSE.choices[0].text
          ...
          eval($CONTENT)
      - pattern: |
          $RESPONSE = openai.Completion.create(...)
          ...
          $CONTENT = $RESPONSE.choices[0].text
          ...
          exec($CONTENT)
      - pattern: |
          $RESPONSE = $CLIENT.chat.completions.create(...)
          ...
          $CONTENT = $RESPONSE.choices[0].message.content
          ...
          eval($CONTENT)
      - pattern: |
          $RESPONSE = $CLIENT.chat.completions.create(...)
          ...
          $CONTENT = $RESPONSE.choices[0].message.content
          ...
          exec($CONTENT)
      - pattern: |
          $RESPONSE = $CLIENT.messages.create(...)
          ...
          $CONTENT = $RESPONSE.content[0].text
          ...
          eval($CONTENT)
      - pattern: |
          $RESPONSE = $CLIENT.messages.create(...)
          ...
          $CONTENT = $RESPONSE.content[0].text
          ...
          exec($CONTENT)
    message: "LLM output flows directly to eval/exec/compile - CRITICAL CODE INJECTION RISK"
    severity: ERROR
    languages: [python]
    metadata:
      category: security
      subcategory: code-injection
      cwe: ["CWE-94"]
      cwe-url: ["https://cwe.mitre.org/data/definitions/94.html"]
      tags: ["code-injection", "eval", "exec", "compile", "llm", "ai-security", "complete", "taint-flow"]
      technology: ["python", "openai", "anthropic", "llm"]
      confidence: "high"
      impact: "critical"
      likelihood: "high"
      description: "Complete taint flow detected: LLM output flows directly from API response to eval/exec/compile functions, indicating a critical code injection vulnerability."
      remediation: "NEVER execute LLM output as code. Use safe parsing, validation, and whitelisting. Use structured output formats (JSON, YAML) instead."
      examples:
        vulnerable: "samples/vulnerable_app.py"
      references:
        - "https://owasp.org/www-community/vulnerabilities/Code_Injection"
        - "https://cwe.mitre.org/data/definitions/94.html"
    paths:
      include:
        - "*.py"

  # Complete taint flow: LLM output -> subprocess
  - id: llm-to-subprocess-complete
    pattern-either:
      - pattern: |
          $RESPONSE = openai.ChatCompletion.create(...)
          ...
          $CONTENT = $RESPONSE.choices[0].message.content
          ...
          subprocess.run($CONTENT, ...)
      - pattern: |
          $RESPONSE = openai.ChatCompletion.create(...)
          ...
          $CONTENT = $RESPONSE.choices[0].message.content
          ...
          subprocess.call($CONTENT, ...)
      - pattern: |
          $RESPONSE = openai.ChatCompletion.create(...)
          ...
          $CONTENT = $RESPONSE.choices[0].message.content
          ...
          subprocess.Popen($CONTENT, ...)
      - pattern: |
          $RESPONSE = openai.ChatCompletion.create(...)
          ...
          $CONTENT = $RESPONSE.choices[0].message.content
          ...
          os.system($CONTENT)
      - pattern: |
          $RESPONSE = openai.Completion.create(...)
          ...
          $CONTENT = $RESPONSE.choices[0].text
          ...
          subprocess.run($CONTENT, ...)
      - pattern: |
          $RESPONSE = openai.Completion.create(...)
          ...
          $CONTENT = $RESPONSE.choices[0].text
          ...
          os.system($CONTENT)
      - pattern: |
          $RESPONSE = $CLIENT.chat.completions.create(...)
          ...
          $CONTENT = $RESPONSE.choices[0].message.content
          ...
          subprocess.run($CONTENT, ...)
      - pattern: |
          $RESPONSE = $CLIENT.chat.completions.create(...)
          ...
          $CONTENT = $RESPONSE.choices[0].message.content
          ...
          os.system($CONTENT)
      - pattern: |
          $RESPONSE = $CLIENT.messages.create(...)
          ...
          $CONTENT = $RESPONSE.content[0].text
          ...
          subprocess.run($CONTENT, ...)
      - pattern: |
          $RESPONSE = $CLIENT.messages.create(...)
          ...
          $CONTENT = $RESPONSE.content[0].text
          ...
          os.system($CONTENT)
    message: "LLM output flows directly to subprocess/os.system - CRITICAL COMMAND INJECTION RISK"
    severity: ERROR
    languages: [python]
    metadata:
      category: security
      subcategory: command-injection
      cwe: ["CWE-78"]
      cwe-url: ["https://cwe.mitre.org/data/definitions/78.html"]
      tags: ["command-injection", "subprocess", "os.system", "llm", "ai-security", "complete", "taint-flow"]
      technology: ["python", "openai", "anthropic", "llm"]
      confidence: "high"
      impact: "critical"
      likelihood: "high"
      description: "Complete taint flow detected: LLM output flows directly from API response to subprocess/os.system functions, indicating a critical command injection vulnerability."
      remediation: "NEVER execute LLM output as shell commands. Use subprocess with shell=False and validate all inputs. Use command whitelists."
      examples:
        vulnerable: "samples/vulnerable_app.py"
      references:
        - "https://owasp.org/www-community/attacks/Command_Injection"
        - "https://cwe.mitre.org/data/definitions/78.html"
    paths:
      include:
        - "*.py"
