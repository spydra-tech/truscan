rules:
  # ============================================================================
  # LLM02: Code Injection - Cohere Generic
  # ============================================================================
  # Detects LLM output used in code execution functions
  # OWASP: LLM02
  # CWE: CWE-94
  # ============================================================================

  - id: cohere-code-injection-eval
    patterns:
      - pattern-either:
          - pattern: |
              $RESPONSE = cohere.Client().chat(...)
          - pattern: |
              $RESPONSE = cohere.ClientV2().chat(...)
          - pattern: |
              $RESPONSE = $CLIENT.chat(...)
          - pattern: |
              $RESPONSE = cohere.Client().generate(...)
          - pattern: |
              $RESPONSE = $CLIENT.generate(...)
      - pattern-either:
          - pattern: eval($VAR)
          - pattern: exec($VAR)
          - pattern: compile($VAR, ...)
      - metavariable-regex:
          metavariable: $VAR
          regex: (code|content|text|output|result|response|command|cmd|str|message|data|resp|answer|\.text|\.message\.content|generations\[0\]\.text|message\.content)
    message: "LLM02: Insecure Output Handling - Cohere output passed to eval/exec/compile (code injection risk)"
    severity: ERROR
    languages: [python]
    metadata:
      category: security
      subcategory: code-injection
      owasp: "LLM02"
      owasp-title: "Insecure Output Handling"
      owasp-url: "https://owasp.org/www-project-top-10-for-large-language-model-applications/LLM_Top_10/LLM02.html"
      cwe: ["CWE-94"]
      cwe-url: ["https://cwe.mitre.org/data/definitions/94.html"]
      tags: ["owasp", "llm02", "insecure-output", "code-injection", "eval", "exec", "compile", "llm", "ai-security", "cohere"]
      technology: ["python", "cohere", "llm"]
      confidence: "high"
      impact: "critical"
      likelihood: "high"
      description: "Cohere output is passed to eval(), exec(), or compile() functions without validation, allowing arbitrary code execution if the LLM output contains malicious code."
      remediation: "Never execute LLM output as code. Use safe parsing and validation instead. Use AST parsing, whitelisted operations, or structured output formats (JSON, YAML) instead of code execution."
      ai_analysis_recommended: true
      examples:
        vulnerable: "samples/cohere_code_injection.py"
      references:
        - "https://owasp.org/www-project-top-10-for-large-language-model-applications/"
        - "https://cwe.mitre.org/data/definitions/94.html"
    paths:
      include:
        - "*.py"

  - id: cohere-code-injection-direct
    patterns:
      - pattern-either:
          # Chat response to eval/exec/compile
          - pattern: |
              $RESPONSE = cohere.Client().chat(...)
              ...
              $VAR = $RESPONSE.text
              ...
              eval($VAR)
          - pattern: |
              $RESPONSE = cohere.Client().chat(...)
              ...
              $VAR = $RESPONSE.message.content
              ...
              eval($VAR)
          - pattern: |
              $RESPONSE = $CLIENT.chat(...)
              ...
              $VAR = $RESPONSE.text
              ...
              exec($VAR)
          - pattern: |
              $RESPONSE = $CLIENT.chat(...)
              ...
              $VAR = $RESPONSE.message.content
              ...
              exec($VAR)
          # Generate response to eval/exec/compile
          - pattern: |
              $RESPONSE = cohere.Client().generate(...)
              ...
              $VAR = $RESPONSE.generations[0].text
              ...
              eval($VAR)
          - pattern: |
              $RESPONSE = $CLIENT.generate(...)
              ...
              $VAR = $RESPONSE.generations[0].text
              ...
              exec($VAR)
          - pattern: |
              $RESPONSE = cohere.Client().generate(...)
              ...
              $VAR = $RESPONSE.generations[0].text
              ...
              compile($VAR, ...)
    message: "LLM02: Insecure Output Handling - Cohere output extracted and passed to eval/exec/compile"
    severity: ERROR
    languages: [python]
    metadata:
      category: security
      subcategory: code-injection
      owasp: "LLM02"
      owasp-title: "Insecure Output Handling"
      owasp-url: "https://owasp.org/www-project-top-10-for-large-language-model-applications/LLM_Top_10/LLM02.html"
      cwe: ["CWE-94"]
      cwe-url: ["https://cwe.mitre.org/data/definitions/94.html"]
      tags: ["owasp", "llm02", "insecure-output", "code-injection", "eval", "exec", "compile", "llm", "ai-security", "cohere", "ai-enhanced"]
      technology: ["python", "cohere", "llm"]
      confidence: "high"
      impact: "critical"
      likelihood: "high"
      description: "Cohere chat or generate output is extracted (from .text, .message.content, or .generations[0].text) and passed directly to eval(), exec(), or compile() functions. This allows arbitrary code execution if the LLM output contains malicious code."
      remediation: "Never execute LLM output as code. Use safe parsing and validation instead. Use AST parsing, whitelisted operations, or structured output formats (JSON, YAML) instead of code execution."
      ai_analysis_recommended: true
      examples:
        vulnerable: "samples/cohere_code_injection.py"
      references:
        - "https://owasp.org/www-project-top-10-for-large-language-model-applications/"
        - "https://cwe.mitre.org/data/definitions/94.html"
    paths:
      include:
        - "*.py"
