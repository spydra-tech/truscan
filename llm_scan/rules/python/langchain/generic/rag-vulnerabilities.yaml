rules:
  # ============================================================================
  # LLM01/LLM03: RAG (Retrieval-Augmented Generation) Vulnerabilities
  # ============================================================================
  # Detects vulnerabilities in RAG chains that combine retrieval with generation
  # 
  # Usage with AI:
  #   python -m llm_scan.runner . --enable-ai-filter \
  #     --ai-analyze-rules langchain-llm01-rag-user-input \
  #     --ai-analyze-rules langchain-llm01-rag-retrieved-to-prompt
  #
  # OWASP: LLM01, LLM03
  # CWE: CWE-79, CWE-94, CWE-502
  # ============================================================================

  - id: langchain-llm01-rag-user-input
    patterns:
      - pattern-either:
          # RAG chain with user input
          - pattern: |
              RetrievalQA.from_chain_type(...).run($USER_INPUT)
          - pattern: |
              RetrievalQAWithSourcesChain.from_chain_type(...).run($USER_INPUT)
          - pattern: |
              $RAG_CHAIN.run($USER_INPUT)
          - pattern: |
              $RAG_CHAIN.invoke($USER_INPUT)
      - metavariable-regex:
          metavariable: $USER_INPUT
          regex: (request\.|input\(|sys\.argv|getenv|environ|args|kwargs|params|query|body|form|json|data|user_input|user_input_text|user_message|user_prompt|prompt_text|raw_input|raw_prompt|user_data|user_content|user_query|query)
    message: "LLM01: Potential Prompt Injection - RAG chain execution with user input"
    severity: WARNING
    languages: [python]
    metadata:
      category: security
      subcategory: injection
      owasp: "LLM01"
      owasp-title: "Prompt Injection (RAG)"
      owasp-url: "https://owasp.org/www-project-top-10-for-large-language-model-applications/LLM_Top_10/LLM01.html"
      cwe: ["CWE-79", "CWE-94"]
      cwe-url: ["https://cwe.mitre.org/data/definitions/79.html", "https://cwe.mitre.org/data/definitions/94.html"]
      tags: ["owasp", "llm01", "prompt-injection", "rag", "retrieval", "langchain", "ai-enhanced"]
      technology: ["python", "langchain", "llm"]
      confidence: "medium"  # Medium confidence - depends on RAG configuration
      impact: "high"
      likelihood: "medium"  # AI will assess RAG chain configuration
      description: "RAG (Retrieval-Augmented Generation) chain is executed with user input. If retrieved documents contain malicious content or user input is not properly sanitized, this can enable prompt injection. AI analysis will determine if the RAG chain configuration is vulnerable."
      remediation: "Validate and sanitize user queries before RAG retrieval. Sanitize retrieved document content before including in prompts. Use delimiters to separate retrieved content from instructions. Implement content filtering for retrieved documents."
      ai_analysis_recommended: true
      examples:
        vulnerable: "samples/langchain_rag.py"
      references:
        - "https://owasp.org/www-project-top-10-for-large-language-model-applications/"
    paths:
      include:
        - "*.py"

  - id: langchain-llm01-rag-retrieved-to-prompt
    mode: taint
    pattern-sources:
      - pattern: |
          $RETRIEVER.get_relevant_documents(...)
      - pattern: |
          $RETRIEVER.invoke(...)
      - pattern: |
          $VECTORSTORE.similarity_search(...)
    pattern-sinks:
      - pattern: |
          ChatPromptTemplate.from_template(...)
      - pattern: |
          PromptTemplate.from_template(...)
      - pattern: |
          f"...{$RETRIEVED}..."
      - pattern: |
          "..." + $RETRIEVED + "..."
      - pattern: |
          $CHAIN.run(...)
      - pattern: |
          $CHAIN.invoke(...)
    message: "LLM01: Indirect Prompt Injection - RAG retrieved documents flow into prompts without sanitization"
    severity: WARNING
    languages: [python]
    metadata:
      category: security
      subcategory: injection
      owasp: "LLM01"
      owasp-title: "Prompt Injection (RAG)"
      owasp-url: "https://owasp.org/www-project-top-10-for-large-language-model-applications/LLM_Top_10/LLM01.html"
      cwe: ["CWE-79", "CWE-94"]
      cwe-url: ["https://cwe.mitre.org/data/definitions/79.html", "https://cwe.mitre.org/data/definitions/94.html"]
      tags: ["owasp", "llm01", "prompt-injection", "indirect-injection", "rag", "langchain", "taint", "ai-enhanced"]
      technology: ["python", "langchain", "llm"]
      confidence: "medium"  # Medium confidence - depends on sanitization
      impact: "high"
      likelihood: "medium"  # AI will assess if sanitization is present
      description: "RAG retrieved documents flow into LangChain prompts or chains. If the vector store contains poisoned content, this enables indirect prompt injection. AI analysis will determine if retrieved content is properly sanitized before use in prompts."
      remediation: "Sanitize all retrieved document content before including in prompts. Use delimiters to separate retrieved content from instructions. Implement content filtering and validation for RAG results. Treat all retrieved content as potentially malicious."
      ai_analysis_recommended: true
      examples:
        vulnerable: "samples/langchain_rag.py"
      references:
        - "https://owasp.org/www-project-top-10-for-large-language-model-applications/"
    paths:
      include:
        - "*.py"

  - id: langchain-llm03-rag-untrusted-sources
    mode: taint
    pattern-sources:
      # Untrusted document sources
      - pattern: |
          requests.get(...).text
      - pattern: |
          urllib.request.urlopen(...).read()
      - pattern: |
          flask.request.files.get(...)
      - pattern: |
          $LOADER.load()
    pattern-sinks:
      - pattern: |
          $VECTORSTORE.from_texts(...)
      - pattern: |
          $VECTORSTORE.from_documents(...)
      - pattern: |
          $RETRIEVER = $VECTORSTORE.as_retriever(...)
    message: "LLM03: Training Data Poisoning - RAG vector store created from untrusted document sources"
    severity: WARNING
    languages: [python]
    metadata:
      category: security
      subcategory: training-data-poisoning
      owasp: "LLM03"
      owasp-title: "Training Data Poisoning"
      owasp-url: "https://owasp.org/www-project-top-10-for-large-language-model-applications/LLM_Top_10/LLM03.html"
      cwe: ["CWE-502"]
      cwe-url: ["https://cwe.mitre.org/data/definitions/502.html"]
      tags: ["owasp", "llm03", "training-data-poisoning", "rag", "vector-store", "langchain", "taint", "ai-enhanced"]
      technology: ["python", "langchain", "llm"]
      confidence: "medium"  # Medium confidence - depends on data source
      impact: "high"
      likelihood: "medium"  # AI will assess data source trustworthiness
      description: "RAG vector store is created from potentially untrusted document sources (web requests, user files, external APIs). This can lead to training data poisoning where malicious content is embedded and later retrieved into prompts. AI analysis will determine if the data source is actually untrusted."
      remediation: "Validate and sanitize all documents before adding to vector stores. Use trusted document sources only. Implement content filtering and validation for external data. Verify data integrity and authenticity before embedding."
      ai_analysis_recommended: true
      examples:
        vulnerable: "samples/langchain_rag.py"
      references:
        - "https://owasp.org/www-project-top-10-for-large-language-model-applications/"
    paths:
      include:
        - "*.py"
