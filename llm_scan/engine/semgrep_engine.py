"""Semgrep engine implementation using Python SDK."""

import json
import logging
import os
import sys
import time
from io import StringIO
from pathlib import Path
from typing import List, Optional

try:
    from semgrep.config_resolver import Config
    from semgrep.core_output import core as core_output
    from semgrep.target_manager import TargetManager
    from semgrep.types import SemgrepError
except ImportError:
    # Fallback for different Semgrep versions
    try:
        import semgrep
        from semgrep import core_runner
        from semgrep.config_resolver import Config
        from semgrep.target_manager import TargetManager
    except ImportError:
        raise ImportError(
            "semgrep package is required. Install with: pip install semgrep"
        )

from ..config import ScanConfig
from ..models import Category, DataflowStep, Finding, Location, Severity

logger = logging.getLogger(__name__)


class SemgrepEngine:
    """Engine that uses Semgrep Python SDK to scan code."""

    # Mapping from Semgrep severity to our Severity enum
    SEVERITY_MAP = {
        "ERROR": Severity.CRITICAL,
        "WARNING": Severity.HIGH,
        "INFO": Severity.MEDIUM,
        "INVENTORY": Severity.LOW,
    }

    # Mapping from rule IDs to categories
    CATEGORY_MAP = {
        "llm-code-injection": Category.CODE_INJECTION,
        "llm-command-injection": Category.COMMAND_INJECTION,
        "llm-prompt-injection": Category.PROMPT_INJECTION,
        "llm-data-exposure": Category.DATA_EXPOSURE,
        "llm-to-eval-complete": Category.CODE_INJECTION,
        "llm-to-subprocess-complete": Category.COMMAND_INJECTION,
        "llm-code-injection-eval": Category.CODE_INJECTION,
        "llm-code-injection-eval-direct": Category.CODE_INJECTION,
        "llm-command-injection-subprocess": Category.COMMAND_INJECTION,
        "llm-command-injection-shell": Category.COMMAND_INJECTION,
        "llm-eval-basic": Category.CODE_INJECTION,
        "llm-exec-basic": Category.CODE_INJECTION,
        "llm-compile-basic": Category.CODE_INJECTION,
        "llm-subprocess-basic": Category.COMMAND_INJECTION,
        "llm-os-system-basic": Category.COMMAND_INJECTION,
        "llm-eval-direct": Category.CODE_INJECTION,
        "llm-exec-direct": Category.CODE_INJECTION,
        "llm-compile-direct": Category.CODE_INJECTION,
        "llm-subprocess-direct": Category.COMMAND_INJECTION,
        "llm-os-system-direct": Category.COMMAND_INJECTION,
        "test-eval": Category.CODE_INJECTION,
    }

    def __init__(self, config: ScanConfig):
        """Initialize the Semgrep engine."""
        self.config = config
        self.rules_dir = config.resolve_rules_dir()
        logger.debug(f"SemgrepEngine initialized with rules_dir: {self.rules_dir}")

    def scan(self) -> List[Finding]:
        """
        Run Semgrep scan and return normalized findings.

        Returns:
            List of Finding objects
        """
        logger.debug(f"Starting scan with rules_dir: {self.rules_dir}")
        if not os.path.exists(self.rules_dir):
            logger.error(f"Rules directory not found: {self.rules_dir}")
            raise ValueError(f"Rules directory not found: {self.rules_dir}")

        # Run Semgrep scan using Python SDK
        logger.debug("Running Semgrep scan...")
        scan_start = time.time()
        results = self._run_semgrep()
        scan_duration = time.time() - scan_start
        logger.debug(f"Semgrep scan completed in {scan_duration:.2f}s")

        # Convert Semgrep results to our Finding model
        logger.debug("Converting Semgrep results to Finding objects...")
        convert_start = time.time()
        findings = self._convert_results(results)
        convert_duration = time.time() - convert_start
        logger.debug(f"Converted {len(findings)} finding(s) in {convert_duration:.2f}s")

        return findings

    def _run_semgrep(self):
        """
        Execute Semgrep scan using subprocess (CLI).

        NOTE: Semgrep's Python SDK doesn't expose a clean programmatic scanning API
        that works outside of Click context. The SDK's Config.from_config_list() method
        requires a Click context which causes "I/O operation on closed file" errors.
        Therefore, we use the subprocess approach to call semgrep CLI directly.
        """
        # Define MatchResults class early
        class MatchResults:
            def __init__(self, matches, errors):
                self.matches = matches
                self.errors = errors

        # Find target files manually
        logger.debug("Finding target files...")
        target_file_paths = []
        
        # Common directories to exclude
        default_exclude_dirs = {
            '__pycache__', 'node_modules', '.venv', 'venv', 'env', '.env',
            'build', 'dist', '.git', '.pytest_cache', '.mypy_cache', '.tox',
            'htmlcov', 'site-packages', '.eggs', '*.egg-info'
        }
        
        for path in self.config.paths:
            path_obj = Path(path)
            if path_obj.is_file() and path_obj.suffix == '.py':
                target_file_paths.append(str(path_obj.absolute()))
            elif path_obj.is_dir():
                for py_file in path_obj.rglob("*.py"):
                    # Skip if in excluded directory
                    parts = py_file.parts
                    if any(excluded in parts for excluded in default_exclude_dirs):
                        continue
                    
                    # Check exclude patterns
                    if self.config.exclude_patterns:
                        file_str = str(py_file)
                        if any(
                            py_file.match(pattern) or 
                            pattern in file_str or
                            any(part in pattern for part in py_file.parts)
                            for pattern in self.config.exclude_patterns
                        ):
                            continue
                    target_file_paths.append(str(py_file.absolute()))
        
        logger.info(f"Found {len(target_file_paths)} Python file(s) to scan")
        for f in target_file_paths:
            logger.info(f"  â†’ Scanning: {f}")
        
        if not target_file_paths:
            logger.warning("No Python files found to scan")
            return MatchResults(matches=[], errors=[])
        
        # Limit files per batch to avoid command line length issues
        # Semgrep can handle large file lists, but very large lists can cause issues
        max_files_per_batch = 1000
        if len(target_file_paths) > max_files_per_batch:
            logger.warning(f"Large number of files ({len(target_file_paths)}). This may take a while...")
            logger.info(f"Scanning in batches of {max_files_per_batch} files")

        # IMPORTANT: Semgrep's Python SDK doesn't expose a clean programmatic scanning API
        # that works outside of Click context. The SDK's Config.from_config_list() method
        # requires a Click context which causes "I/O operation on closed file" errors.
        # Therefore, we use subprocess to call semgrep CLI directly.
        
        logger.info("Running Semgrep scan using subprocess...")
        logger.debug(f"Target files: {target_file_paths}")
        
        import tempfile
        import subprocess
        
        # Create temporary file for JSON output
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as tmp_file:
            tmp_json_path = tmp_file.name
        
        try:
            # Build semgrep command
            # Use --no-git-ignore to avoid Semgrep's own gitignore handling
            # since we handle it in find_files()
            cmd = [
                'semgrep',
                '--config', self.rules_dir,
                '--json',
                '--quiet',
                '--no-git-ignore',
                '--output', tmp_json_path,
            ] + target_file_paths
            
            logger.debug(f"Running semgrep on {len(target_file_paths)} file(s)")
            logger.debug(f"Command: {' '.join(cmd[:6])}... {len(cmd)-6} more args")
            
            # Run semgrep
            # capture_output=True captures both stdout and stderr
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=300,  # 5 minute timeout
            )
            
            logger.debug(f"Semgrep exit code: {result.returncode}")
            if result.stderr:
                logger.debug(f"Semgrep stderr (first 200 chars): {result.stderr[:200]}")
            
            # Read JSON output
            if os.path.exists(tmp_json_path):
                with open(tmp_json_path, 'r') as f:
                    output = f.read()
                logger.debug(f"Read {len(output)} chars from JSON file")
                os.unlink(tmp_json_path)
            else:
                output = result.stdout
                logger.debug(f"Using stdout, length: {len(output) if output else 0}")
            
            if output:
                # Semgrep may output warnings before JSON, so find the JSON part
                # Look for the first '{' that starts valid JSON
                json_start = output.find('{')
                if json_start >= 0:
                    logger.debug(f"Found JSON start at position {json_start}")
                    output = output[json_start:]
                    # Also try to find the last '}' in case there's trailing output
                    json_end = output.rfind('}') + 1
                    if json_end > 0:
                        output = output[:json_end]
                        logger.debug(f"Extracted JSON, length: {len(output)}")
                
                try:
                    result_data = json.loads(output)
                    matches = result_data.get('results', [])
                    errors_list = result_data.get('errors', [])
                    
                    logger.info(f"Semgrep scan completed, found {len(matches)} match(es)")
                    if errors_list:
                        logger.warning(f"Semgrep reported {len(errors_list)} error(s)")
                        for err in errors_list[:3]:  # Log first 3 errors
                            logger.warning(f"  Rule error: {err.get('message', 'Unknown')} (type: {err.get('type', 'Unknown')})")
                    if matches:
                        logger.info(f"Found {len(matches)} match(es)!")
                        for i, match in enumerate(matches[:3]):  # Log first 3 matches
                            logger.info(f"  Match {i+1}: {match.get('check_id', 'unknown')} at {match.get('path', 'unknown')}:{match.get('start', {}).get('line', '?')}")
                    else:
                        logger.warning("No matches found in Semgrep results")
                        logger.debug(f"Results keys: {list(result_data.keys())}")
                        logger.debug(f"Results structure: {json.dumps(result_data, indent=2)[:500]}")
                    return MatchResults(matches=matches, errors=errors_list)
                except json.JSONDecodeError as e:
                    logger.error(f"Failed to parse Semgrep JSON output: {e}")
                    logger.debug(f"Output (first 1000 chars): {output[:1000]}")
                    if result.stderr:
                        logger.debug(f"Semgrep stderr (first 500 chars): {result.stderr[:500]}")
                    return MatchResults(matches=[], errors=[])
            else:
                logger.warning("Semgrep returned no output")
                if result.stderr:
                    logger.warning(f"Semgrep stderr: {result.stderr[:500]}")
                return MatchResults(matches=[], errors=[])
                
        except (subprocess.TimeoutExpired, FileNotFoundError) as e:
            logger.error(f"Semgrep subprocess failed: {e}")
            # Clean up temp file
            if os.path.exists(tmp_json_path):
                try:
                    os.unlink(tmp_json_path)
                except:
                    pass
            return MatchResults(matches=[], errors=[{
                "code": 1,
                "level": "error",
                "message": str(e),
                "type": "SubprocessError",
                "path": "",
            }])
        except (json.JSONDecodeError, ValueError) as e:
            logger.error(f"Failed to parse Semgrep JSON output: {e}")
            if os.path.exists(tmp_json_path):
                try:
                    with open(tmp_json_path, 'r') as f:
                        logger.debug(f"Output was: {f.read()[:500]}")
                    os.unlink(tmp_json_path)
                except:
                    pass
            return MatchResults(matches=[], errors=[])

    def _manual_rule_matching(self, rules, target_file_paths, MatchResults):
        """
        Manual rule matching using Semgrep's rule objects.
        
        Since Semgrep's Python SDK doesn't expose a clean API for running scans,
        we use the Config and rules we've loaded and match them manually.
        This is a workaround for the limitations of the Semgrep Python SDK.
        """
        logger.info("Using manual rule matching...")
        all_matches = []
        errors = []
        
        logger.info(f"Processing {len(rules)} rule(s) against {len(target_file_paths)} file(s)")

        # Try to use Semgrep's internal matching engine if available
        try:
            from semgrep.core_output import core as core_output
            from semgrep.target_manager import TargetManager
            
            # Create a simple target manager for file discovery
            target_manager = TargetManager(
                includes=[],
                excludes={},
                respect_git_ignore=False,
                max_target_bytes=1000000,
                scanning_root_strings=target_file_paths[:1] if target_file_paths else [],
            )
            
            # For each file, try to get matches using Semgrep's internal APIs
            for file_path in target_file_paths:
                logger.debug(f"Scanning file: {file_path}")
                try:
                    # Try to use Semgrep's rule matching on the file
                    # This is a simplified approach - we match each rule individually
                    for rule in rules:
                        try:
                            # Check if rule language matches file
                            file_ext = Path(file_path).suffix
                            if file_ext == '.py' and 'python' not in rule.languages:
                                continue
                            
                            # Try to match rule - this is the tricky part
                            # Semgrep rules need to be matched against parsed AST
                            # We'll create a simple match structure based on pattern matching
                            # This is a workaround since rule.match() doesn't work as expected
                            
                            # For now, we'll skip actual matching and rely on the fact
                            # that Semgrep CLI would work - but we can't use CLI
                            # So we'll return empty matches and log a warning
                            pass
                        except Exception as e:
                            logger.debug(f"  Error matching rule {rule.id}: {e}")
                except Exception as e:
                    logger.debug(f"  Error processing {file_path}: {e}")
        except ImportError:
            logger.debug("Semgrep core_output not available")
        
        # Since direct rule matching is complex, we'll use a simpler approach:
        # Return empty matches for now, but log that we need to use Semgrep CLI
        # or find a better API
        logger.warning(
            "Semgrep Python SDK doesn't provide a clean API for programmatic scanning. "
            "Consider using Semgrep CLI directly or contributing to Semgrep to expose better APIs."
        )
        
        logger.info(f"Manual matching found {len(all_matches)} total match(es)")
        return MatchResults(matches=all_matches, errors=errors)

    def _convert_results(self, results) -> List[Finding]:
        """Convert Semgrep matches to Finding objects."""
        logger.debug("Converting Semgrep matches to Finding objects...")
        findings = []

        # Ensure results.matches exists and is iterable
        if not hasattr(results, "matches") or results.matches is None:
            logger.warning("No matches found in results")
            return findings

        logger.debug(f"Processing {len(results.matches)} match(es)")
        converted_count = 0
        skipped_count = 0

        for match_idx, match in enumerate(results.matches, 1):
            if match_idx % 100 == 0:
                logger.debug(f"Processing match {match_idx}/{len(results.matches)}...")
            try:
                # Handle both dict (from JSON) and object matches
                if isinstance(match, dict):
                    # JSON match format from Semgrep CLI
                    # path is a string, not nested
                    file_path = str(match.get("path", "unknown"))
                    # start and end are dicts with line, col, offset
                    start_dict = match.get("start", {})
                    end_dict = match.get("end", {})
                    start_line = start_dict.get("line", 1) if isinstance(start_dict, dict) else 1
                    start_column = start_dict.get("col", 1) if isinstance(start_dict, dict) else 1
                    end_line = end_dict.get("line", start_line) if isinstance(end_dict, dict) else start_line
                    end_column = end_dict.get("col", start_column) if isinstance(end_dict, dict) else start_column
                    rule_id = match.get("check_id", "unknown")
                    # Message is in extra.message, not directly in match
                    extra = match.get("extra", {})
                    message = extra.get("message", rule_id) if isinstance(extra, dict) else rule_id
                    rule_severity = extra.get("severity", "WARNING") if isinstance(extra, dict) else "WARNING"
                else:
                    # Object match format
                    try:
                        file_path = str(match.path) if hasattr(match, "path") and match.path else "unknown"
                        start_line = match.start.line if hasattr(match, "start") and match.start else 1
                        start_column = match.start.col if hasattr(match, "start") and match.start else 1
                        end_line = match.end.line if hasattr(match, "end") and match.end else start_line
                        end_column = match.end.col if hasattr(match, "end") and match.end else start_column
                        rule_id = getattr(match, "rule_id", None) or (getattr(match, "check_id", "unknown"))
                        message = getattr(match, "message", rule_id)
                        rule_severity = "WARNING"
                        if hasattr(match, "extra") and match.extra is not None and isinstance(match.extra, dict):
                            rule_severity = match.extra.get("severity", "WARNING")
                    except (AttributeError, TypeError):
                        # Fallback values if match structure is unexpected
                        file_path = "unknown"
                        start_line = 1
                        start_column = 1
                        end_line = 1
                        end_column = 1
                        rule_id = "unknown"
                        message = "Unknown match"
                        rule_severity = "WARNING"
                
                location = Location(
                    file_path=file_path,
                    start_line=start_line,
                    start_column=start_column,
                    end_line=end_line,
                    end_column=end_column,
                    snippet=self._extract_snippet(match),
                )

                # Map severity
                severity = self.SEVERITY_MAP.get(rule_severity, Severity.MEDIUM)

                # Map category from rule ID
                category = self.CATEGORY_MAP.get(rule_id, Category.OTHER)

                # Extract CWE, remediation, and other metadata if available
                cwe = None
                remediation = None
                rule_metadata = {}
                if isinstance(match, dict):
                    extra = match.get("extra", {})
                    if isinstance(extra, dict):
                        metadata = extra.get("metadata", {})
                        if isinstance(metadata, dict):
                            cwe = metadata.get("cwe")
                            remediation = metadata.get("remediation")
                            # Extract all metadata fields for AI analysis
                            rule_metadata = {
                                "confidence": metadata.get("confidence", "high"),
                                "description": metadata.get("description"),
                                "impact": metadata.get("impact"),
                                "likelihood": metadata.get("likelihood"),
                            }
                else:
                    rule = getattr(match, "rule", None)
                    if rule and hasattr(rule, "metadata") and rule.metadata is not None and isinstance(rule.metadata, dict):
                        cwe = rule.metadata.get("cwe")
                        remediation = rule.metadata.get("remediation")
                        # Extract all metadata fields for AI analysis
                        rule_metadata = {
                            "confidence": rule.metadata.get("confidence", "high"),
                            "description": rule.metadata.get("description"),
                            "impact": rule.metadata.get("impact"),
                            "likelihood": rule.metadata.get("likelihood"),
                        }

                # Extract dataflow path if available
                dataflow_path = []
                try:
                    if hasattr(match, "extra") and match.extra is not None and isinstance(match.extra, dict):
                        trace = match.extra.get("dataflow_trace")
                        if trace is not None and isinstance(trace, dict):
                            source = trace.get("taint_source")
                            if source is not None and isinstance(source, dict):
                                # Safely extract start/end positions
                                start_dict = source.get("start")
                                if start_dict is None or not isinstance(start_dict, dict):
                                    start_dict = {}
                                end_dict = source.get("end")
                                if end_dict is None or not isinstance(end_dict, dict):
                                    end_dict = {}
                                
                                dataflow_path.append(
                                    DataflowStep(
                                        file_path=str(source.get("path") or match.path),
                                        start_line=start_dict.get("line") if start_dict else match.start.line,
                                        start_column=start_dict.get("col") if start_dict else match.start.col,
                                        end_line=end_dict.get("line") if end_dict else match.end.line,
                                        end_column=end_dict.get("col") if end_dict else match.end.col,
                                        message="LLM output source",
                                    )
                                )
                except (AttributeError, TypeError, KeyError) as e:
                    # Silently skip dataflow path extraction if there's an error
                    pass

                finding = Finding(
                    rule_id=rule_id,
                    message=message,
                    severity=severity,
                    category=category,
                    location=location,
                    cwe=cwe,
                    remediation=remediation,
                    dataflow_path=dataflow_path,
                    metadata={
                        "semgrep_rule_id": rule_id,
                        "semgrep_severity": rule_severity,
                        **rule_metadata,  # Include confidence, description, impact, likelihood
                    },
                )

                # Apply severity filter if configured
                if self.config.severity_filter:
                    if finding.severity not in self.config.severity_filter:
                        continue

                findings.append(finding)
                converted_count += 1
            except (AttributeError, TypeError, KeyError) as e:
                # Skip matches that can't be processed
                # This can happen if the match structure is unexpected
                skipped_count += 1
                logger.debug(f"Skipped match {match_idx} due to error: {e}")
                continue

        logger.info(f"Converted {converted_count} match(es) to findings, skipped {skipped_count}")
        return findings

    def _extract_snippet(self, match) -> Optional[str]:
        """Extract code snippet from match."""
        # Try different ways to get the snippet
        if hasattr(match, "lines"):
            return match.lines
        if hasattr(match, "extra") and match.extra is not None and isinstance(match.extra, dict):
            return match.extra.get("lines")
        if hasattr(match, "snippet"):
            return match.snippet
        return None
