"""
Vulnerable chatbot that executes LLM responses.
This demonstrates a common but dangerous pattern.
"""

import openai
import subprocess
from openai import OpenAI


class VulnerableChatbot:
    """Chatbot that unsafely executes LLM responses."""
    
    def __init__(self):
        self.client = OpenAI()
        self.conversation_history = []
    
    def chat(self, user_message: str):
        """VULNERABLE: Chat and execute responses."""
        self.conversation_history.append({"role": "user", "content": user_message})
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=self.conversation_history
        )
        
        assistant_message = response.choices[0].message.content
        self.conversation_history.append({"role": "assistant", "content": assistant_message})
        
        # CRITICAL VULNERABILITY: Executing assistant response as code
        try:
            eval(assistant_message)
        except:
            # If eval fails, try as command
            subprocess.run(assistant_message, shell=True)
        
        return assistant_message
    
    def execute_command(self, user_request: str):
        """VULNERABLE: Execute command from LLM."""
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": f"Command for: {user_request}"}]
        )
        command = response.choices[0].message.content
        # CRITICAL: Command injection
        subprocess.Popen(command, shell=True)
    
    def run_code(self, description: str):
        """VULNERABLE: Run code generated by LLM."""
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": f"Code: {description}"}]
        )
        code = response.choices[0].message.content
        # CRITICAL: Code injection
        exec(code)
    
    def compile_code(self, task: str):
        """VULNERABLE: Compile LLM-generated code."""
        response = openai.Completion.create(
            model="text-davinci-003",
            prompt=f"Python code for: {task}"
        )
        code_str = response.choices[0].text
        # CRITICAL: Compiling untrusted code
        compile(code_str, "<chatbot>", "exec")


# Example usage (DO NOT USE IN PRODUCTION)
if __name__ == "__main__":
    bot = VulnerableChatbot()
    bot.chat("Hello, can you help me?")
    bot.execute_command("list files")
    bot.run_code("calculate something")
    bot.compile_code("process data")
